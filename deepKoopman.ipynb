{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch as tr\n",
    "from torch import nn\n",
    "import torch.optim as opt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchmetrics.regression import MeanSquaredError, MeanAbsoluteError\n",
    "import pandas as pd\n",
    "import matplotlib as mt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import typing\n",
    "from typing import Callable, Tuple\n",
    "import matplotlib as mt\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define device to use (cpu/gpu)\n",
    "if tr.cuda.is_available():\n",
    "  print('# of GPUs available: ', tr.cuda.device_count())\n",
    "  print('First GPU type: ',tr.cuda.get_device_name(0))\n",
    "device = ('cuda' if tr.cuda.is_available() else 'cpu')\n",
    "print(f\"Computation device: {device}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning for universal linear embeddings of nonlinear dynamics “Koopman operator”\n",
    "\n",
    "In this work we try to replicate (and possibly improve) the results of the work done in this [PAPER](https://www.nature.com/articles/s41467-018-07210-0), in which they focus on developing DNN representations of Koopman eigenfunctions that remain interpretable and parsimonious, even for high-dimensional and strongly nonlinear systems.\n",
    "\n",
    "\n",
    "**Koopman operator:** <p>\n",
    "The Koopman operator is a linear operator that describes the evolution of scalar observables (i.e., measurement functions of the states) in an infinitedimensional Hilbert space. This operator theoretic point of view lifts the dynamics of a finite-dimensional nonlinear system to an infinite-dimensional function space where the evolution of the original system becomes linear, indeed, the eigenfunctions of the Koopman operator provide intrinsic coordinates that globally linearize the dynamics.\n",
    "\n",
    "\n",
    "**Dataset:** <p>\n",
    "All data can be reconstructed using the code available at [GIT](https://github.com/BethanyL/DeepKoopman).\n",
    "\n",
    "\n",
    "**Network architecture:** <p>\n",
    "\n",
    "We implement the original architecture of the above-mentioned paper, which will be discussed in detail below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical formulation of Koopman theory\n",
    "The object of the discussion are discrete-time dynamical systems:\n",
    "$$\\textbf{x}_{k+1} = \\textbf{F}(\\textbf{x}_k)$$\n",
    "where $\\textbf{x} \\in \\mathbb{R}^n $ is the state of the system and $\\textbf{F}$ represents the dynamics that map the state of the system forward in time. In the case of linear dynamics, the map $\\textbf{F}$ is a matrix that advances the state $\\textbf{x}$ and the dynamics of these linear systems admit a universal solution in terms of the eigenvalues and eigenvectors of the matrix $\\textbf{F}$. \n",
    "In 1931, B.O. Koopman provided an alternative description of dynamical systems in terms of the evolution of functions in the Hilbert space of possible measurements $\\textbf{g}(\\textbf{x})$ of the state. The so-called *Koopman operator*, $\\mathcal{K}$, that advances measurement functions is an infinite-dimensional linear operator such that\n",
    "\n",
    "$$\\mathcal{K}\\textbf{g} := \\textbf{g}\\ \\circ \\textbf{F}\\ \\ \\ \\text{i.e.}\\ \\ \\mathcal{K}\\textbf{g}(\\textbf{x}_k) = \\textbf{g}(\\textbf{x}_{k+1})$$\n",
    "\n",
    " Representing nonlinear dynamics in a linear framework, via the Koopman operator, has the potential to enable advanced nonlinear prediction using the theory developed for linear systems. However, obtaining finite-dimensional approximations of the infinite-dimensional Koopman operator has proven challenging in practical applications. In many approaches, they try to identify eigenfunctions of the Koopman operator directly, satisfying:\n",
    "\n",
    " $$\\varphi(\\textbf{x}_{k+1}) = \\mathcal{K} \\varphi(\\textbf{x}_k) = \\lambda \\varphi(\\textbf{x}_k).$$\n",
    "\n",
    " In practice, Koopman eigenfunctions may be more difficult to obtain than the solution of the discrete dynamics evolution equation we wrote in the begininning, however, these eigenfunctions are guaranteed to span an invariant subspace, and the Koopman operator will yield a matrix when restricted to this subspace, thus arriving at a description of the evolution of the system in terms of a finite dimensional linear operator."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Handling\n",
    "The authors of the study we are following found Koopman eigenfunctions in several example systems, including a simple model with a discrete spectrum and two examples that exhibit a continuous spectrum: the nonlinear pendulum and the high-dimensional unsteady fluid flow past a cylinder. They created the datasets by solving the systems of differential equations in MATLAB using the ode45 solver.\n",
    "\n",
    "For each dynamical system, they choose 5000 initial conditions for the test set, 5000 for the validation set, and 5000 - 20000 for the training set. For each initial condition, the differential equations were solved for some time span.\n",
    "\n",
    "We decided to not generate new data, but to import the ones they already used in order to compare the results. These datasets can be found in the above-mentioned github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max number of initial conditions to be considered in order to build the train, validation and test datasets. If it is set to 'None', all possible initial conditions are taken.\n",
    "max_initial_conditions=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "option                           =1\n",
    "exp=[                            # Options: \n",
    "     \"DiscreteSpectrumExample\",  # 1)\n",
    "     \"FluidFlowBox\",             # 2)\n",
    "     \"FluidFlowOnAttractor\",     # 3)\n",
    "     \"Pendulum\"                  # 4)\n",
    "     ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network architecture\n",
    "\n",
    "In this work they tried to identify only a *few key* intrinsic coordinates $\\textbf{y} = \\varphi(\\textbf{x})$ spanned by a set of Koopman eigenfunctions $\\varphi: \\mathbb{R}^p \\rightarrow \\mathbb{R}^n$, in the context of a dynamical system $\\textbf{y}_{k+1}=\\textbf{Ky}_k$. In particular, intrinsic coordinates which are useful in order to recostruct the dynamics are those for which $\\textbf{y} = \\varphi(\\textbf{x})$, hence, the state x can be recovered with the inverse $\\textbf{x} = \\varphi^{-1}(\\textbf{y})$ so that the state x may be recovered. This is achieved using an auto-encoder (in the following picture), where the action of $\\varphi$ is implemented by the encoder and the action of $\\varphi^{-1}$ by the decoder. The dimension p of the auto-encoder subspace is a hyperparameter of the network that the authors of the paper have chosen guided by knowledge of the system and subsequently tuned. So we decided to follow their choices.\n",
    "\n",
    "<img src=\"https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-018-07210-0/MediaObjects/41467_2018_7210_Fig1_HTML.png?as=webp\" style=\"width: 40%; margin-left: 30%; margin-right: 30%;\"/>\n",
    "\n",
    "The network have some hidden layer in the encoder and in the decoder whose number and width depends on the specific system. They are followed by an activation with the ReLU. The output layers of the encoder and the decoder are linear.\n",
    "\n",
    "Moreover, they generalized this framework to include a broad class of nonlinear systems that exhibit a continuous eigenvalue spectrum $\\lambda$. A continuous spectrum is characterized by a continuous range of observed frequencies, as opposed to the discrete spectrum consisting of isolated, fixed frequencies. This phenomena is observed in a wide range of physical systems that exhibit broadband frequency content, such as turbulence and nonlinear optics. The continuous spectrum spoils the simple Koopman descriptions, as there is not a straightforward finite approximation in terms of a small number of eigenfunctions. Indeed, away from the linear regime, an infinite Fourier sum is required to approximate the shift in frequency and eigenfunctions due to the non linearity.\n",
    "To deal with this problem, they allowed the eigenvalues of the matrix $\\textbf{K}$ to vary, parametrized by the function $\\lambda = \\Lambda(\\textbf{y})$, which is learned by an auxiliary network (in the following figure). The eigenvalues $\\lambda_{\\pm} = \\mu \\pm i \\omega$ are then used to parametrize block-diagonal $\\textbf{K}(\\mu,\\omega)$.\n",
    "In particular, they built separate auxiliary networks, one for the complex conjugate pair of eigenvalues and one for the the real eigenvalue. In this way, we can avoid to perform an infinite asymptotic expansion of the eigenfunctions. So, the resulting networks remain parsimonious, and the few key eigenfunctions are interpretable.\n",
    "\n",
    "<img src=\"https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-018-07210-0/MediaObjects/41467_2018_7210_Fig2_HTML.png?as=webp\" style=\"width: 40%; margin-left: 30%; margin-right: 30%;\"/>\n",
    "\n",
    "\n",
    "\n",
    "Also in this case, we have hidden layers whose number and dimension vary according to the specific system and the output layer is linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if option not in range(1,5):\n",
    "    raise Exception(\"Option invalid, please stick with the option proposed...\")\n",
    "dataDir=\"data/\"\n",
    "match exp[option-1]:\n",
    "    case \"DiscreteSpectrumExample\":\n",
    "        coor         =2                     # Number of generalized spatial coordinates of the experiment.\n",
    "        max_tr       =3                     # Number of files provided by the authors for training.\n",
    "        dimEncoder   =[30,30,2]             # Width of Encoder (the input layer has dimension `coor` and it is implicit, the dimension of the last layer is the dimension of the finite-dimensional representation of Koopman space).\n",
    "        dimAuxNet    =[10,10,10]            # Width of Auxiliary Network \n",
    "                                            #   (first dimension is implicit and it is the dimension of the Koopman subspace, last one is implicit and it is\n",
    "                                            #   the number of parameters needed to construct the Jordan Matrix)\n",
    "        RE_IMG_eigAux=(2,0)                 #   number of real eigenvalues of the K Jordan matrix (1x1 blocks) and of complex eigenvalues (2x2 blocks).\n",
    "        impRadialSymm=True                  # If setted to `True` give to the Auxiliary net radial distance from the origin of the encoded point (if setted to `False` give the coordinates)\n",
    "        numShift     =30                    # Lenght of the trajectories considered for the prediction part of the loss\n",
    "        numLinShift  =50                    # Lenght of the trajectories condidered for the linear-evolution part of the loss\n",
    "        lamb         =[0.1,0.1,1.0,1e-7]    # Relative weights of various loss contributions.\n",
    "        lamb_l2      =1e-15                 # L2 regularizing loss weight.\n",
    "        lr           =1e-3                  # Learning rate.\n",
    "        Dt           =0.02                  # Time scale of the experiment, it represent the difference in time between two temporal steps in the trajectories.\n",
    "        lenTrj       =51                    # Lenght of integrated trajectory in the provided files.\n",
    "        batchSize    =256                   # Batch size (all computation on batch elementes are indipendent and parallelizable). \n",
    "                                            #   The loss and the metric results are taken as the mean on a batch.\n",
    "        \"\"\"\n",
    "        The Network geometry is: \n",
    "                                                                                                                        \n",
    "              Encoder                                           Decoder   \n",
    "            +-----------\\                                   ------------+\n",
    "            |         |\\ -----\\        K matrix         ---/  |         |\n",
    "            |         | \\      ----\\               ----/      |         |\n",
    "            |         |  \\          --------------/           |         |\n",
    "            |         |   \\           |         |             |         |\n",
    "            |         |    \\          |         |             |         |\n",
    "            |         |     \\         |         |             |         |\n",
    "            |         |      |        |         |             |         |\n",
    "            |         |      \\     -----------------          |         |\n",
    "            |         |    -------/   |        /    \\------   |         |\n",
    "            +-------------/    \\     /        /            \\------------+\n",
    "                       -\\       \\    |       /                           \n",
    "                         \\       \\   |      /                            \n",
    "                         \\       \\  |     /                             \n",
    "                          -\\      \\/    -/                              \n",
    "                            -------|   /                                \n",
    "                            |      |  /                                 \n",
    "                            |      | /                                  \n",
    "                            |      |/                                   \n",
    "                            +------/                                    \n",
    "                         Auxiliary net        \n",
    "        \n",
    "        The Encoder is constituted by `len(dimEncoder)` linear layers. All the layers except for the last one are followed by a\n",
    "        ReLU activation layer, which injects non-linearity in the Encoder. The decoder has the same structure but in reverse order:\n",
    "        the first layer has not a ReLU applied to it (as it is the input layer), and provides the dimension of the subspace in which\n",
    "        the Koopman operator is finitely-represented, while the output is in the phase space (has the same dimension as the input of the Encoder).\n",
    "        The K-matrix is a block-diagonal Jordan matrix in which the real eigenvalues are associated to 1x1 blocks, parametrized by μ [exp(μ*Δt)];\n",
    "        the complex eigenvalues are associated to 2x2 blocks, parametrized by μ, ω:    exp(μ*Δt)*[[ cos(ω*Δt),-sin(ω*Δt)],\n",
    "                                                                                                  [ sin(ω*Δt), cos(ω*Δt)]]\n",
    "        In order to determine the values of μ and ω, there exists an Auxiliary Network constitued by `len(dimAuxNet)` linear layers\n",
    "        followed by a ReLU (except for the last one).\n",
    "        \"\"\"\n",
    "        seqEncoder=(\n",
    "                    nn.Linear(coor          ,dimEncoder[0]),nn.ReLU(),\n",
    "                    nn.Linear(dimEncoder[0] ,dimEncoder[1]),nn.ReLU(),\n",
    "                    nn.Linear(dimEncoder[1] ,dimEncoder[2])\n",
    "                    )\n",
    "        seqDecoder=(\n",
    "                    nn.Linear(dimEncoder[2] ,dimEncoder[1]),nn.ReLU(),\n",
    "                    nn.Linear(dimEncoder[1] ,dimEncoder[0]),nn.ReLU(),\n",
    "                    nn.Linear(dimEncoder[0] ,coor         )\n",
    "                    )\n",
    "        tmpAuxInputDim=dimEncoder[-1] if not impRadialSymm else 1\n",
    "        auxNet    =(\n",
    "                    nn.Linear(tmpAuxInputDim,dimAuxNet[0]),nn.ReLU(),\n",
    "                    nn.Linear(dimAuxNet[0]  ,dimAuxNet[1]),nn.ReLU(),\n",
    "                    nn.Linear(dimAuxNet[1]  ,dimAuxNet[2]),nn.ReLU(),\n",
    "                    nn.Linear(dimAuxNet[2]  ,1           )\n",
    "                    )\n",
    "    case \"FluidFlowBox\":\n",
    "        coor         =3\n",
    "        max_tr       =4\n",
    "        dimEncoder   =[130,3]\n",
    "        dimAuxNet    =[20,20]\n",
    "        RE_IMG_eigAux=(1,1)\n",
    "        impRadialSymm=False\n",
    "        numShift     =30\n",
    "        numLinShift  =100\n",
    "        lamb         =[0.1,0.1,1.0,1e-9]\n",
    "        lamb_l2      =1e-13\n",
    "        lr           =1e-3\n",
    "        Dt           =0.01\n",
    "        lenTrj       =101\n",
    "        batchSize    =128\n",
    "        seqEncoder=(\n",
    "                    nn.Linear(coor          ,dimEncoder[0]),nn.ReLU(),\n",
    "                    nn.Linear(dimEncoder[0] ,dimEncoder[1])\n",
    "                    )\n",
    "        seqDecoder=(\n",
    "                    nn.Linear(dimEncoder[1] ,dimEncoder[0]),nn.ReLU(),\n",
    "                    nn.Linear(dimEncoder[0] ,coor         )\n",
    "                    )\n",
    "        tmpAuxInputDim=dimEncoder[-1] if not impRadialSymm else 1\n",
    "        auxNet    =(\n",
    "                    nn.Linear(tmpAuxInputDim,dimAuxNet[0]),nn.ReLU(),\n",
    "                    nn.Linear(dimAuxNet[0]  ,dimAuxNet[1]),nn.ReLU(),\n",
    "                    nn.Linear(dimAuxNet[1]  ,1           )\n",
    "                    )\n",
    "\n",
    "    case \"FluidFlowOnAttractor\":\n",
    "        max_tr       =3\n",
    "        coor         =3\n",
    "        dimEncoder   =[105,2]\n",
    "        dimAuxNet    =[300]\n",
    "        RE_IMG_eigAux=(0,1)\n",
    "        impRadialSymm=True\n",
    "        numShift     =30\n",
    "        numLinShift  =120 \n",
    "        lamb         =[0.1,0.1,1.0,1e-7]\n",
    "        lamb_l2      =1e-13\n",
    "        lr           =1e-3\n",
    "        Dt           =0.05\n",
    "        lenTrj       =121\n",
    "        batchSize    =256\n",
    "        seqEncoder=(\n",
    "                    nn.Linear(coor          ,dimEncoder[0]),nn.ReLU(),\n",
    "                    nn.Linear(dimEncoder[0] ,dimEncoder[1])\n",
    "                    )\n",
    "        seqDecoder=(\n",
    "                    nn.Linear(dimEncoder[1] ,dimEncoder[0]),nn.ReLU(),\n",
    "                    nn.Linear(dimEncoder[0] ,coor         )\n",
    "                    )\n",
    "        tmpAuxInputDim=dimEncoder[-1] if not impRadialSymm else 1\n",
    "        auxNet    =(\n",
    "                    nn.Linear(tmpAuxInputDim,dimAuxNet[0]),nn.ReLU(),\n",
    "                    nn.Linear(dimAuxNet[0]  ,1           )\n",
    "                    )\n",
    "\n",
    "    case \"Pendulum\":\n",
    "        max_tr       =6\n",
    "        coor         =2\n",
    "        dimEncoder   =[80,80,2]\n",
    "        dimAuxNet    =[170]\n",
    "        RE_IMG_eigAux=(0,1)\n",
    "        impRadialSymm=True\n",
    "        numShift     =30\n",
    "        numLinShift  =50 \n",
    "        lamb         =[0.001,0.001,1.0,1e-9]\n",
    "        lamb_l2      =1e-14\n",
    "        lr           =1e-3\n",
    "        Dt           =0.02\n",
    "        lenTrj       =51\n",
    "        batchSize    =128\n",
    "        seqEncoder=(\n",
    "                    nn.Linear(coor          ,dimEncoder[0]),nn.ReLU(),\n",
    "                    nn.Linear(dimEncoder[0] ,dimEncoder[1]),nn.ReLU(),\n",
    "                    nn.Linear(dimEncoder[1] ,dimEncoder[2])\n",
    "                    )\n",
    "        \n",
    "        seqDecoder=(\n",
    "                    nn.Linear(dimEncoder[2] ,dimEncoder[1]),nn.ReLU(),\n",
    "                    nn.Linear(dimEncoder[1] ,dimEncoder[0]),nn.ReLU(),\n",
    "                    nn.Linear(dimEncoder[0] ,coor         )\n",
    "                    )\n",
    "        tmpAuxInputDim=dimEncoder[-1] if not impRadialSymm else 1\n",
    "        auxNet    =(\n",
    "                    nn.Linear(tmpAuxInputDim,dimAuxNet[0]),nn.ReLU(),\n",
    "                    nn.Linear(dimAuxNet[0]  ,1           )\n",
    "                    )\n",
    "    case EXP:\n",
    "        raise Exception(f\"Experiment Option not found.... [{EXP}]\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "filesTrain=[dataDir+exp[option-1]+\"_train\"+str(i)+\"_x.csv\" for i in range(1,max_tr+1)]\n",
    "fileVali=dataDir+exp[option-1]+\"_val_x.csv\"\n",
    "fileTest=dataDir+exp[option-1]+\"_test_x.csv\"\n",
    "print(\"Experiment\",exp[option-1]+\", files train:\")\n",
    "for f in filesTrain:\n",
    "    print(\"\\t\\t\"+f)\n",
    "print(\"\\nFile Validation:\\t\",fileVali)\n",
    "print(\"File Test:\\t\\t\",fileTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customDataSet(Dataset):\n",
    "    '''\n",
    "    Dataset used to train, validate and test the model, \n",
    "        It is a dataset array (can be subscripted) and its i-th element is a trajectory constitued by `Nshift` elements \n",
    "    '''\n",
    "    def __init__(self, filenames: str|list[str], coor: int, Nshift: int, NLshift: int, lenTraje: int, debug: bool = False) -> None:\n",
    "        '''\n",
    "        `filenames` indicates a filename or a list of filenames where the data are stored. If provided a list of names it will concatenate their contents.\n",
    "        `coor`      indicates the number of coordinates in the phase space trajectories.\n",
    "        `Nshift`     indicates the lenght of the trajectories to be considered (it must be <= than `lenTraje`) for the prediction part of the loss\n",
    "        `NLshift`    indicates the lenght of the trajectories to be considered (it must be <= than `lenTraje`) for the linear-evolution part of the loss\n",
    "        `lenTraje`  it is the lenght of the trajectories in the csv file (generated by integration algorithms)\n",
    "        `debug`     if set to 'True', it adds a private attribute to the class named _dataPD, and it is a pandas DataFrame containing all the data read.\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self._data=tr.Tensor([])\n",
    "        self._Nshift =Nshift\n",
    "        self._NLshift=NLshift\n",
    "        self._maxNshift=max(Nshift,NLshift)\n",
    "        self._coor=coor\n",
    "        self._event4file=[]\n",
    "        names=[\"x_\"+str(i) for i in range(coor)]\n",
    "        multiplefiles=False\n",
    "        if isinstance(filenames,list):\n",
    "            L=len(filenames)\n",
    "            if L>1:\n",
    "                multiplefiles=True\n",
    "            else:\n",
    "                filenames=filenames[0]\n",
    "        if multiplefiles:\n",
    "            self._dataPD=pd.concat([pd.read_csv(f,header=None,names=names) for f in filenames])\n",
    "        else:\n",
    "            self._dataPD=pd.read_csv(filenames,names=names) \n",
    "        \n",
    "        if (lenTraje<=self._maxNshift):\n",
    "            raise Exception(f\"Trajectories in file is lenTraje={lenTraje} long, but you want to extract {self._maxNshift} time steps\")\n",
    "        IC=len(self._dataPD)//lenTraje\n",
    "        for i in range(IC if max_initial_conditions==None or IC<max_initial_conditions else max_initial_conditions):\n",
    "            tmp=[tr.tensor(self._dataPD[i*lenTraje+j:i*lenTraje+j+self._maxNshift+1].values).unsqueeze(0).float() for j in range(lenTraje-self._maxNshift)]\n",
    "            self._data=tr.cat((self._data,*tmp)) # This will put as first dimension the  numebr of time-shift, the second-one is the batch size and third the number of coordinates\n",
    "\n",
    "        if not debug:\n",
    "            self._dataPD=None\n",
    "\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        '''\n",
    "        return the number of initial conditions aka the number of examined trajectories(the length of them are the maximub between `Nshift` and `NLshift`) \n",
    "        '''\n",
    "        return len(self._data)\n",
    "\n",
    "    def __getitem__(self,i: int) -> tr.tensor:\n",
    "        '''\n",
    "        return the trajectory with i-th initial conditions\n",
    "        N.B. if `lenTraje` > max(`Nshift`,`NLshift`) and i-th initial condition is multiple of `lenTraje` (a true different trajectory)\n",
    "             the (i+1)-th initial condition will be i-th trajectory shifted in future by one time-step\n",
    "        '''\n",
    "        return self._data[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the datasets for training, validate and test the model using the files listed above  ^ ^ ^\n",
    "DATA_TR=customDataSet(filesTrain,coor,numShift,numLinShift,lenTrj)\n",
    "DATA_VL=customDataSet(fileVali  ,coor,numShift,numLinShift,lenTrj)\n",
    "DATA_TS=customDataSet(fileTest  ,coor,numShift,numLinShift,lenTrj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the datasets we create DataLoaders that group our datasets in batches\n",
    "train=DataLoader(DATA_TR,batch_size=batchSize,shuffle=True ,drop_last=True)\n",
    "vali =DataLoader(DATA_TR,batch_size=batchSize,shuffle=True ,drop_last=True)\n",
    "test =DataLoader(DATA_TR,batch_size=batchSize,shuffle=False,drop_last=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "The loss function they decided to use (and obviously the architecture itself) enforces constraints specifically designed to extract the fewest meaningful eigenfunctions; it consists of three weighted mean-squared error components: a reconstruction loss $\\mathcal{L}_{recon}$, included in order to obtain a good reconstruction accuracy of the auto-encoder, the loss future state prediction $\\mathcal{L}_{pred}$, necessary to have intrinsic coordinates that allow future state prediction,  linearity of dynamics loss $\\mathcal{L}_{lin}$, which enforces linear prediction over m time steps. They also use a $\\mathcal{L}_{\\infty}$\n",
    " term to penalty the data point with the largest loss. They also add $ℓ_2$\n",
    " regularization on the weights W to reduce overfitting. We decided to not do that because and we simply thought to make the weights smaller by adding a weight decay to Adam. However, as pointed out in [this paper](https://openreview.net/pdf?id=rk6qdGgCZ), the two things do not coincide, but we still found it effective in reducing overfitting. Their loss is:\n",
    " $$ \\mathcal{L} = \\alpha_1 (\\mathcal{L}_{recon} + \\mathcal{L}_{pred}) + \\mathcal{L}_{lin} + \\alpha_2 \\mathcal{L}_{\\infty} + \\alpha_3 ||\\textbf{W}||^2_2$$\n",
    " \n",
    " $$ \\mathcal{L}_{recon} = ||\\textbf{x}_1 - \\varphi^{-1}(\\varphi(\\textbf{x}_1))||_{\\text{MSE}}$$\n",
    " $$ \\mathcal{L}_{pred} = \\frac{1}{S_p} \\sum_{m=1}^{S_p} ||\\textbf{x}_{m+1} -  \\varphi^{-1}(K^m \\varphi(\\textbf{x}_1))||_{\\text{MSE}}$$\n",
    " $$ \\mathcal{L}_{lin} = \\frac{1}{T - 1} \\sum_{m=1}^{T-1} ||\\varphi(\\textbf{x}_{m+1}) - K^m \\varphi(\\textbf{x}_1)||_{\\text{MSE}}$$\n",
    "  $$ \\mathcal{L}_{\\infty} = ||\\textbf{x}_1 - \\varphi^{-1}(\\varphi(\\textbf{x}_1))||_{\\infty} + ||\\textbf{x}_2 - \\varphi^{-1}(K\\varphi(\\textbf{x}_1))||_{\\infty}$$\n",
    "  where $\\text{MSE}$ refers to mean squared error and T is the number of time steps in each trajectory. The weights $\\alpha_1$, $\\alpha_2$, and $\\alpha_3$ are hyperparameters which are different for each example. The integer $S_p$ is a hyperparameter for how many steps to check in the prediction loss. In our case we do not have the term proportional to $|| W ||_2^2|| $ and the weight decay was set equal to $\\alpha_3$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    '''\n",
    "    The loss proposed in the paper was made up of 5 differents conponents.\n",
    "    - The first one is a \"reconstruction\" loss. It is computed using MSELoss between the first time-step of a trajectory and the same encoded and then decoded without\n",
    "        using the K-matrix to evolve temporally the point. It checks the goodness of the reconstruction of the input data. (it will impose that the autoencoder part \n",
    "        approximates the identity transformation so the encoding transformation could be interpreted as a geometric non-linear change of basis).\n",
    "    - The second one is responsible for the predictive power of the Network, it will compare the point shifted in time (without using the Koopman matrix) with the \n",
    "        with the correspondent one, encoded and evolved applying different times the Koopman matrix and then decoded.\n",
    "        `Nshift`     indicates the lenght of the trajectories to be considered for this part of the loss\n",
    "    - The third one has to impose the linearity of the tranformation that evolves in time the system (trying to decouple the geometric transformation and the time evolution).\n",
    "        it is calculated computing the MSELoss between the true encoded version of a point of a trajectory in the Koopman subspace, and the correspondent one evolved from \n",
    "        the first point (it is similar to the second one but in Koopman subspace). \n",
    "        `NLshift`    indicates the lenght of the trajectories to be considered for this part of the loss\n",
    "    - The fourth is the L∞ norm between a point and its encoded-decoded version, and between a point shifted one step in the future and its prediction.\n",
    "    The last contribution is the L2 regularisation of the weights. It is needed to avoid overfitting and to enforce that the value of weights is near 0, to exploit at its best\n",
    "    the non-linearity of the activation functions. We choose to implement this regularisation loss using a `weight_decay` in the Adam Optimizer, as standard procedure to \n",
    "    regularize weights in pytorch. This method it's almost identical to a L2 regularisation (the contribution in the loss is proportional to the magnitude of the weights), \n",
    "    but we found out there are some differences highlighted in a paper found at link https://openreview.net/pdf?id=rk6qdGgCZ\n",
    "    '''\n",
    "    def __init__(self, Nshift: int, NLshift: int, lamb: Tuple[float, float, float, float]) -> None:\n",
    "        super().__init__()\n",
    "        self._Nshift =Nshift\n",
    "        self._NLshift=NLshift\n",
    "        self._lamb   =lamb\n",
    "        self.loss_reco=nn.MSELoss()\n",
    "        self.loss_pred=nn.MSELoss()\n",
    "        self.loss_line=nn.MSELoss()\n",
    "        self.loss_linf: Callable[[tr.tensor,tr.tensor,tr.tensor,tr.tensor],tr.tensor]=\\\n",
    "            lambda x,y,x1,y1: ((x-y).abs().max(dim=-1)[0]+(x1-y1).abs().max(dim=-1)[0]).mean()\n",
    "\n",
    "    #XT contains the true time-evolved starting from the initials points of trajectories in a batch, YT the predicted ones.\n",
    "    def forward(self, XT: tr.tensor, YT: tr.tensor, phiT: tr.tensor, phiPredT: tr.tensor) -> tr.tensor:\n",
    "        if len(XT)<=max(self._NLshift,self._Nshift):\n",
    "            raise Exception(f\"The data provided to calculate loss haven't enough elements to fulfill the requirement of\\\n",
    "                              {self._Nshift} time steps for the prediciton loss and {self._NLshift} for the linear part [len(X)={len(XT)}]\")\n",
    "\n",
    "        totLoss=        self.loss_reco(XT[0],YT[0]) * self._lamb[0]    # better not to use implace operation += to preserve possibility to backpropagate\n",
    "                                                                       # the gradient using the computational graph created by pythorch\n",
    "        totLoss=totLoss+self.loss_pred(XT[1:self._Nshift+1],YT[1:self._Nshift+1])           * self._lamb[1]\n",
    "        totLoss=totLoss+self.loss_line(phiT[1:self._NLshift+1],phiPredT[1:self._NLshift+1]) * self._lamb[2]\n",
    "        totLoss=totLoss+self.loss_linf(XT[0],YT[0],XT[1],YT[1])                             * self._lamb[3]\n",
    "\n",
    "        return  totLoss\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric   = MeanAbsoluteError() # As metric we used the MAE between a point evolved one time step in the future and the correspondent prediction done by the Net\n",
    "loss     = CustomLoss(numShift,numLinShift,lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    '''\n",
    "    This the implementation of the Encoder\n",
    "    '''\n",
    "    def __init__(self,layers: Tuple[nn.Module, ...]) -> None:\n",
    "        super().__init__()\n",
    "        self.layers=nn.Sequential(*layers)\n",
    "    def forward(self,x: tr.tensor) -> tr.tensor:\n",
    "        return self.layers(x)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    '''\n",
    "    This the implementation of the Decoder\n",
    "    '''\n",
    "    def __init__(self, layers: Tuple[nn.Module, ...]) -> None:\n",
    "        super().__init__()\n",
    "        self.layers=nn.Sequential(*layers)\n",
    "    def forward(self, x: tr.tensor) -> tr.tensor:\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "#==================================================================================================\n",
    "#--------------------------------------------------------------------------------------------------\n",
    "#==================================================================================================\n",
    "\n",
    "class REAL_AuxNet(nn.Module):\n",
    "    '''\n",
    "    The Auxiliary Net provides the parametrization for one real value, but we need different parameters according\n",
    "    to the block that we want to construct. `REAL_AuxNet` provides one parameters: μ\n",
    "    '''\n",
    "    def __init__(self, layers: Tuple[nn.Module, ...]) -> None:\n",
    "        super().__init__()\n",
    "        self.layers=nn.Sequential(*layers)\n",
    "    def forward(self, x: tr.tensor) -> tr.tensor:\n",
    "        return self.layers(x)\n",
    "        \n",
    "class COMPLEX_AuxNet(nn.Module):\n",
    "    '''\n",
    "    The Auxiliary Net provide the parametrization of one real value, but we need different parameters according\n",
    "    to the block that we want to construct. `COMPLEX_AuxNet` provides, using two `REAL_AuxNet`, the parameters μ, ω\n",
    "    '''\n",
    "    def __init__(self, layers: Tuple[nn.Module, ...]) -> None:\n",
    "        super().__init__()\n",
    "        # Real part parameter μ AuxNet\n",
    "        self.AuxR=REAL_AuxNet(layers)\n",
    "        # Immaginary part parameter ω AuxNet\n",
    "        self.AuxI=REAL_AuxNet(deepcopy(layers)) # We used a `deepcopy` of the layers because we want them \n",
    "                                                #    with indipendent parameters (different location in memory)\n",
    "    def forward(self,x: tr.tensor) -> tr.tensor:\n",
    "        return self.AuxR(x), self.AuxI(x)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------\n",
    "#--------------------------------------------------------------------------------------------------\n",
    "\n",
    "class _RealEntry(nn.Module):\n",
    "    '''\n",
    "    `_RealEntry` takes as input `Dt` (difference in time between two adiacent steps) and the tensor from which we extract the information to determine\n",
    "    the value of the continuous parameters. It outputs a 1x1 block.\n",
    "    '''\n",
    "    def __init__(self, layers: Tuple[nn.Module, ...], RealComplex_EigenValues: Tuple[int, int], Dt: float) -> None:\n",
    "        '''\n",
    "        `layers` is a tuple containing the layers for the Auxiliary Network.\n",
    "        `RealComplex_EigenValues` is a tuple with the number of 1x1 blocks related with real eigenvalues, and the number of 2x2 blocks\n",
    "                                  related to the complex eigenvalues of the Jordan matrix rappresenting the evolution in time.\n",
    "        '''\n",
    "        super().__init__()\n",
    "        # Number of Real 1x1 blocks\n",
    "        self._NReal=RealComplex_EigenValues[0]\n",
    "        # Total width of Jordan matrix (n rows and n columns)\n",
    "        self.n=self._NReal+RealComplex_EigenValues[1]*2\n",
    "        self.Dt=Dt\n",
    "\n",
    "        # Modules to generate all the parameters we need to create the real blocks\n",
    "        for i in range(self._NReal):\n",
    "            tmp=deepcopy(layers) # We used a `deepcopy` of the layers because we want them with indipendent parameters (different location in memory)\n",
    "            self.add_module(str(i),REAL_AuxNet(tmp))\n",
    "\n",
    "    def forward(self,indexBlock: int,x: tr.tensor) -> tr.tensor:\n",
    "        u=self[indexBlock](x)\n",
    "        # -------------- Block\n",
    "        R=tr.exp(u*self.Dt)\n",
    "        # --------------------\n",
    "        return R\n",
    "    def __getitem__(self,index: int) -> nn.Module:\n",
    "        return getattr(self,str(index))\n",
    "\n",
    "\n",
    "class _JordanBlock(nn.Module):\n",
    "    '''\n",
    "    `_JordanBlock` takes as input `Dt` (difference in time between two adiacent steps) and the tensor from which extract the information to determine\n",
    "    the value of the continuous parameters. It outputs a block 2x2 as an array of dimension 4+(`n`-2) with 2 entries with true parameters,\n",
    "    (`n`-2) zeros padded and other 2 entries. This procedure is done in this way because for technical reasons we preferred to compose the Jordan matrix \n",
    "    starting from an array with lenght n*n made of the blocks concatenated, reshaped to a \"n x n\" tensor.\n",
    "    '''\n",
    "    def __init__(self, layers: Tuple[nn.Module, ...], RealComplex_EigenValues: Tuple[int, int], Dt: float, BatchSize: int =1) -> None:\n",
    "        '''\n",
    "        `layers` is a tuple containing the layers for the Auxiliary Network.\n",
    "        `RealComplex_EigenValues` is a tuple with the number of 1x1 blocks related with real eigenvalues, and the number of 2x2 blocks\n",
    "                                  related to the complex eigenvalues of the Jordan matrix rappresenting the evolution in time.\n",
    "        '''\n",
    "        super().__init__()\n",
    "        # Number of Complex 2x2 blocks\n",
    "        self._NComplex=RealComplex_EigenValues[1]\n",
    "        # Total width of Jordan matrix (n rows and n of columns)\n",
    "        self.n=RealComplex_EigenValues[0]+self._NComplex*2\n",
    "        self.Dt=Dt\n",
    "        self._batchSize=BatchSize\n",
    "\n",
    "        # Modules to generate all the needed parameters for complex blocks\n",
    "        for i in range(self._NComplex):\n",
    "            tmp=deepcopy(layers) # We used a `deepcopy` of the layers because we want them with indipendent parameters (different location in memory)\n",
    "            self.add_module(str(i),COMPLEX_AuxNet(tmp))\n",
    "        # Register buffer to move it with model from CPU to GPU\n",
    "        self.register_buffer('_PAD', tr.zeros((self._batchSize,self.n-2),requires_grad=True))\n",
    "\n",
    "    def forward(self,indexBlock: int,x: tr.tensor) -> tr.tensor:\n",
    "        u,w=self[indexBlock](x)\n",
    "        R=tr.exp(u*self.Dt)\n",
    "        PAD=self._PAD\n",
    "        # -------------- Block\n",
    "        Block=tr.cat([R*tr.cos(w*self.Dt),-R*tr.sin(w*self.Dt),PAD,R*tr.sin(w*self.Dt),R*tr.cos(w*self.Dt)],dim=-1) \n",
    "        # --------------------\n",
    "        return Block\n",
    "    def __getitem__(self,index: int) -> nn.Module:\n",
    "        return getattr(self,str(index))\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------\n",
    "#--------------------------------------------------------------------------------------------------\n",
    "\n",
    "class customMatrix(nn.Module):\n",
    "    '''\n",
    "    This Net will merge the various Jordan Blocks and compose the torch tensor representing the matrix. The blocks are composed choosing the real\n",
    "    parameters starting from the point in the Koopman subspace of my system (the output of the decoder).\n",
    "    `Dt` is the difference in time between two adiacent steps.\n",
    "    '''\n",
    "    def __init__(self, layers: Tuple[nn.Module, ...], RealComplex_EigenValues: Tuple[int, int], Dt: float, BatchSize: int =1) -> None:\n",
    "        '''\n",
    "        `layers` is a tuple containing the layers for the Auxiliary Network.\n",
    "        `RealComplex_EigenValues` is a tuple with the number of 1x1 blocks related with real eigenvalues, and the number of 2x2 blocks\n",
    "                                  related to the complex eigenvalues of the Jordan matrix rappresenting the evolution in time.\n",
    "        '''\n",
    "        super().__init__()\n",
    "        # We store the number of real and complex blocks\n",
    "        self._NReal,self._NComplex=RealComplex_EigenValues\n",
    "        # We compute the width of the matrix\n",
    "        self.n=self._NReal+self._NComplex*2\n",
    "        # We store the required Networks to fix the parameters of the matrix\n",
    "        if self._NComplex>0: self._JB=_JordanBlock(layers,RealComplex_EigenValues,Dt,BatchSize)\n",
    "        if self._NReal>0:    self._RE=_RealEntry(layers,RealComplex_EigenValues,Dt)\n",
    "\n",
    "        self._batchSize=BatchSize\n",
    "        # Register buffer to move it with model from CPU to GPU\n",
    "        self.register_buffer('_PAD', tr.zeros((self.n,self._batchSize),requires_grad=True))\n",
    "        \n",
    "    def forward(self,x: tr.tensor) -> tr.tensor:\n",
    "        # Here we'll store the tensors, from now it will contain the list of blocks to concatenate\n",
    "        matrixlist=[]\n",
    "\n",
    "        for i in range(self.n):\n",
    "            for j in range(self.n):\n",
    "                addedBlock=False\n",
    "                # The matrix is built putting first the complex blocks on the diagonal\n",
    "                if i==j and i%2==0 and i<self._NComplex*2:                  #        |\n",
    "                    # COMPLEX BLOCKS                                        #        |\n",
    "                    B=self._JB(i//2,x).T                                    #        | \n",
    "                    matrixlist.append(B)                                    #        |  \n",
    "                    addedBlock=True                                         #        |  \n",
    "                                                                            #        /  \n",
    "                # Then the real blocks  <-------------------------__________________/\n",
    "                elif i==j and i >=self._NComplex*2:\n",
    "                    # REAL BLOCKS\n",
    "                    B=self._RE(i-self._NComplex*2,x).T\n",
    "                    matrixlist.append(B)\n",
    "                    addedBlock=True\n",
    "\n",
    "                if addedBlock:\n",
    "                    # We Padd with zeros between blocks to center them in the diagonal after the reshape\n",
    "                    PAD=self._PAD\n",
    "                    matrixlist.append(PAD)\n",
    "        # We concatenate the blocks\n",
    "        matrix=tr.cat(matrixlist[:-1])\n",
    "        # We shape them as a matrix\n",
    "        matrix=matrix.reshape((self.n,self.n,self._batchSize))\n",
    "        # We permute the axes to have the batch dimension as the first one and to perform operations on the batches in parallel\n",
    "        matrix=matrix.permute((2,0,1)) \n",
    "        return matrix\n",
    "\n",
    "#==================================================================================================\n",
    "#--------------------------------------------------------------------------------------------------\n",
    "#==================================================================================================\n",
    "\n",
    "class K_Matrix(nn.Module):\n",
    "    '''\n",
    "    `K_Matrix` is the realization of the whole process of fixing the continous parameters and applying the matrix. It is responsible of the evolution\n",
    "    in time. It acts on the Koopman subspace.\n",
    "    If it is initialized with `radialSymmetry` setted to True, the matrix eigenvalues will be calculated from vector lenght information (not direction)\n",
    "    `Dt` difference in time between two adiacent steps\n",
    "    '''\n",
    "    def __init__(self, layersAuxNets: Tuple[nn.Module, ...], RealComplex_EigenValues: Tuple[int, int], Dt: float, radialSymmetry: bool =False, BatchSize: int =1) -> None:\n",
    "        super().__init__()\n",
    "        # We store the number of real and complex blocks\n",
    "        self._NReal,self._NComplex=RealComplex_EigenValues\n",
    "        # We compute the width of the matrix\n",
    "        self.n=self._NReal+self._NComplex*2\n",
    "        self._radialSymmetry=radialSymmetry\n",
    "        self.matrix=customMatrix(layersAuxNets,RealComplex_EigenValues,Dt,BatchSize)\n",
    "\n",
    "    def forward(self,x: tr.tensor) -> tr.tensor:\n",
    "        if self.n != len(x[0]):\n",
    "            raise Exception(f\"Jordan Koopman matrix has dimension {self.n}x{self.n} but input has dimension {len(x[0])}....\")\n",
    "        \n",
    "        # We compose the Jordan matrix fixing the real parameters:\n",
    "\n",
    "        # If radial symmetry is set to `True`, the input for the Auxiliary Network is only the magnitude of the vector, not the direction\n",
    "        xtmp=x if not self._radialSymmetry else x.norm(dim=-1).unsqueeze(-1)\n",
    "        M=self.matrix(xtmp)\n",
    "        # We evolve in time applying the matrix product between the point in Koopman subspace and the Jordan matrix\n",
    "        res=M.bmm(x.unsqueeze(-1)).squeeze(-1) # N.B. the matrix is shaped (`batchSize`,`n`,`n`) with `n` the dimension of the Koopman subspace.\n",
    "                                               #      to perform batch matrix multplication we had to tranform the vector in a `n`x 1 matrix \n",
    "                                               #      (`batchSize`,`n`,1). Than we had to squeeze back the result in vectorial form (`batchSize`,`n`)\n",
    "        return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KOOPMAN(nn.Module):\n",
    "    '''\n",
    "    KOOPMAN Net is the whole composition of encoder, K_matrix (the matrix in itself and all the auxiliary networks) and decoder\n",
    "    If it is initialized with `radialSymmetry` setted to True, the K_matrix eigenvalues will be calculated from vector lenght information (not direction)\n",
    "    `Dt` difference in time between two adiacent steps\n",
    "    '''\n",
    "    def __init__(self\n",
    "                , layersEncoder: Tuple[nn.Module, ...]\n",
    "                , layersDecoder: Tuple[nn.Module, ...]\n",
    "                ,  layersAuxNet: Tuple[nn.Module, ...]\n",
    "                ,  RealComplex_EigenValues: Tuple[int, int], Dt: float, NShift: int, radialSymmetry: bool =False, BatchSize: int =1) -> None:\n",
    "        '''\n",
    "        `Dt` is the time elapsed between two different trajecory points\n",
    "        `NShift` is the number of time-shifts considered (the lenght of the trajectory).\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.ENC=Encoder(layersEncoder)\n",
    "        self.K=K_Matrix(layersAuxNets=layersAuxNet,RealComplex_EigenValues=RealComplex_EigenValues,Dt=Dt,radialSymmetry=radialSymmetry,BatchSize=BatchSize)\n",
    "        self.DEC=Decoder(layersDecoder)\n",
    "        self.NShift=NShift\n",
    "        self._batchSize=BatchSize\n",
    "\n",
    "    def forward(self, XT: tr.tensor) -> Tuple[tr.tensor,tr.tensor,tr.tensor,tr.tensor]:\n",
    "        '''\n",
    "        The input of the Net is a (`numShift+1`,`batchSize`,`coord`) `XT`, the first dimension indicates time position in the trajectory, the second\n",
    "        one the batch dimension, the third one the geometric dimension of generalized spatial coordinate in the phase space of the experiment.\n",
    "        '''\n",
    "        PhiT=self.ENC(XT)   # This will encode all the coodinates at all the times\n",
    "        arr=[]              # This will contain all the subsequents time steps evolved from the initial condition in Koopman subspace \n",
    "        arr.append(PhiT[0]) # Fisrt of all we put in it the initial condition\n",
    "\n",
    "        # We evolved temporally the point and by stored the result in `PhiPredT`, it will contain the predicted trajectory in Koopman subspace from the initial condition\n",
    "        #   at `numShift` subsequent times\n",
    "        for i in range(self.NShift):\n",
    "            arr.append(self.K(arr[i])) # Takes the last time step and evolve it by `Dt` (it applies the K matrix one time)\n",
    "        \n",
    "        PhiPredT=tr.cat(arr).reshape((self.NShift+1,self._batchSize,-1))\n",
    "        YT=self.DEC(PhiPredT) # This will encode all the predictions back in phase space\n",
    "        return XT, YT, PhiT,PhiPredT\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxShift=max(numShift,numLinShift) # The model will provide prediction to fulfill the bigger requirement in term of \n",
    "                                   # time-shift in the future, then the custom loss use only the needed time-spans\n",
    "model=KOOPMAN(layersEncoder=seqEncoder\n",
    "             ,layersDecoder=seqDecoder\n",
    "             ,layersAuxNet=auxNet\n",
    "             ,RealComplex_EigenValues=RE_IMG_eigAux,Dt=Dt,NShift=maxShift,radialSymmetry=impRadialSymm,BatchSize=batchSize)\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Procedure\n",
    "\n",
    "They initialized each weight matrix W randomly from a uniform distribution in the range $[-s, s]$ for $s = \\frac{1}{\\sqrt{a}}$, where $a$ is the dimension of the input of the layer. Each bias vector $b$ is initialized to 0. The learning rate for the Adam optimizer is 0.001. We also use early stopping; for each model, at the end of training, we resume the step with the lowest validation error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=500  # Number of epochs for the training\n",
    "patience=7  # If after `patience` epochs the model did not improve, the training is automatically stopped\n",
    "optim= opt.Adam(params=model.parameters(),lr=lr,weight_decay=lamb_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping(Exception):\n",
    "    '''\n",
    "    Custom exception to raise in case of stop due to number of epochs in which the model did not improve greater than `patience`.\n",
    "    '''\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "    \n",
    "\n",
    "\n",
    "class SaveBestModel:\n",
    "    '''\n",
    "    This utility is needed to save the best model (choosen using the one that minimizes the loss on the validation dataset) and to check if\n",
    "    any improvement as occurred during last epochs.\n",
    "    `best_valid_loss` is the minimum of the loss found\n",
    "    `best_epoch`      is the epoch at witch the validation was minimal\n",
    "    `patience`        is the maximum number of epochs that we consider the model to have the potential of improving over the last updating\n",
    "    '''\n",
    "    def __init__(self,patience=100, best_vali_loss=float('inf')) -> None: # object initialized with best_loss = +∞\n",
    "        self.best_vali_loss = best_vali_loss\n",
    "        self.patience=patience\n",
    "        self.best_epoch=0\n",
    "        self._fromLastUpdate=0\n",
    "        \n",
    "    def __call__(\n",
    "        self, current_vali_loss: float, epoch: int,\n",
    "        model: nn.Module, \n",
    "        optimizer: opt.Optimizer,\n",
    "        criterion: Callable[[tr.tensor,tr.tensor],float], \n",
    "        metric: float\n",
    "    ):\n",
    "        if current_vali_loss < self.best_vali_loss:\n",
    "            # Private attribute containing the last epochs in which the model improved\n",
    "            self._fromLastUpdate=0\n",
    "            self.best_vali_loss = current_vali_loss\n",
    "            print(f\"\\nBest validation loss: {self.best_vali_loss}\")\n",
    "            print(f\"\\nSaving best model for epoch: {epoch+1}\\n\")\n",
    "            # method to save a model (the state_dict: a python dictionary object that \n",
    "            # maps each layer to its parameter tensor) and other useful parametrers\n",
    "            # see: https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "            tr.save({\n",
    "                     'epoch': epoch+1,\n",
    "                     'model_state_dict': model.state_dict(),\n",
    "                     'optimizer_state_dict': optimizer.state_dict(),\n",
    "                     'loss': criterion,\n",
    "                     'metric': metric\n",
    "                    },\n",
    "                    'best_model.pth')\n",
    "            self.best_epoch=epoch+1\n",
    "        else:\n",
    "            self._fromLastUpdate+=1\n",
    "\n",
    "        # Trow an exception if model has to stop due to early stopping\n",
    "        if self._fromLastUpdate>self.patience:\n",
    "            raise EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_best_model=SaveBestModel(patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists containing history during epochs of:\n",
    "h_loss_tr  =[] # loss on train dataset\n",
    "h_metric_tr=[] # metric on train dataset\n",
    "h_loss_vl  =[] # loss on validation dataset\n",
    "h_metric_vl=[] # metric on validation dataset\n",
    "\n",
    "metric.to(device)\n",
    "model=model.to(device)\n",
    "for e in range(EPOCHS):\n",
    "    t0=time.time()\n",
    "    # Put model in train mode\n",
    "    model.train()\n",
    "    lossVal=0.0\n",
    "    metrVal=0.0\n",
    "    nbatch=0\n",
    "    # Loop for each batch in all the train dataset\n",
    "    for x in train:\n",
    "        x=x.to(device).swapaxes(0,1)\n",
    "        nbatch+=1\n",
    "        XT, YT, PhiT,PhiPredT=model(x)\n",
    "        l=loss(XT, YT, PhiT,PhiPredT)\n",
    "        m=metric(XT[1],YT[1])\n",
    "        l.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "        lossVal+=l.item()\n",
    "        metrVal+=m.item()\n",
    "        \n",
    "    # Normalize the loss and the metric to have the mean value between all the batches\n",
    "    lossVal/=nbatch\n",
    "    metrVal/=nbatch\n",
    "    h_loss_tr.append(lossVal)\n",
    "    h_metric_tr.append(metrVal)\n",
    "\n",
    "    # Put model in evaluation mode\n",
    "    model.eval()\n",
    "    vl_lossVal=0.0\n",
    "    vl_metrVal=0.0\n",
    "    nbatch=0\n",
    "    # Loop for each batch in all the validation dataset\n",
    "    for x in vali:\n",
    "        nbatch+=1\n",
    "        x=x.to(device).swapaxes(0,1)\n",
    "        XT, YT, PhiT,PhiPredT=model(x)\n",
    "        l=loss(XT, YT, PhiT,PhiPredT)\n",
    "        m=metric(XT[1],YT[1])\n",
    "        vl_lossVal+=l.item()\n",
    "        vl_metrVal+=m.item()\n",
    "    vl_lossVal/=nbatch\n",
    "    vl_metrVal/=nbatch\n",
    "    h_loss_vl.append(vl_lossVal)\n",
    "    h_metric_vl.append(vl_metrVal)\n",
    "\n",
    "    elapsed_time = time.time()-t0    \n",
    "    print(f\"epoch: {e+1}, time(s): {elapsed_time:.2f}, train loss: {lossVal:.6f}, train metric: {metrVal:.6f}, vali loss: {vl_lossVal:.6f}, vali metric: {vl_metrVal:.6f}\")\n",
    "    try: \n",
    "        save_best_model(vl_lossVal,e,model,optim,metric,metrVal)\n",
    "    except EarlyStopping:\n",
    "        print(f\"Early Stopping occurred at epoch: {e+1}, best validation loss is {save_best_model.best_vali_loss}\")\n",
    "        break\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch=save_best_model.best_epoch\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(range(1,len(h_loss_tr)+1),   h_loss_tr, color='green', linestyle='-', label='train loss')\n",
    "plt.plot(range(1,len(h_loss_vl)+1),  h_loss_vl, color='blue', linestyle='-', label='validation loss')\n",
    "plt.axvline(best_epoch,color=\"r\",linestyle=\"--\",label=\"best epoch\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(range(1,len(h_metric_tr)+1),  h_metric_tr,  color='green', linestyle='-', label='train metric')\n",
    "plt.plot(range(1,len(h_metric_vl)+1),  h_metric_vl, color='blue', linestyle='-', label='validation metric')\n",
    "plt.axvline(best_epoch,color=\"r\",linestyle=\"--\",label=\"best epoch\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Metric')\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "metric.cpu()\n",
    "best_model = tr.load('best_model.pth') # Load best model from file\n",
    "best_model_epoch = best_model['epoch']\n",
    "print(f\"Best model was saved at {best_model_epoch} epochs\\n\")\n",
    "model.load_state_dict(best_model['model_state_dict']) # Fill model with saved parameters\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "ts_lossVal=0.0\n",
    "ts_metrVal=0.0\n",
    "nbatch=0\n",
    "maxShift=max(numShift,numLinShift)\n",
    "# Loop for each batch in all the test dataset\n",
    "tmpArrXT=[] # these are temporary array to store all the original data and prediction\n",
    "tmpArrYT=[] #   |\n",
    "totXT=None  #   \\__--> We will put the tensors concatenated in `totXT` and `totYT`\n",
    "totYT=None\n",
    "for x in test:\n",
    "    nbatch+=1\n",
    "    x=x.cpu().swapaxes(0,1)\n",
    "    XT, YT, PhiT,PhiPredT=model(x)\n",
    "    l=loss(XT, YT, PhiT,PhiPredT)\n",
    "    m=metric(XT[1],YT[1])\n",
    "    ts_lossVal+=l.item()\n",
    "    ts_metrVal+=m.item()\n",
    "    tmpArrXT.append(XT)\n",
    "    tmpArrYT.append(YT)\n",
    "totXT=tr.cat(tmpArrXT,dim=1).cpu() # I `cat` them along the batch dimension, the first dimension will remain the 'time dimension',\n",
    "totYT=tr.cat(tmpArrYT,dim=1).cpu() #    the second one will contain the various trajectories and the last one the coordinates.\n",
    "ts_lossVal/=nbatch\n",
    "ts_metrVal/=nbatch\n",
    "print(f\"Loss value on TEST dataset:\\t{ts_lossVal}\\nMetric on TEST dataset:\\t\\t{ts_metrVal}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs\n",
    "\n",
    "In order to test our model we considered the following plots:\n",
    "\n",
    "1) The correlation $ \\langle \\textbf{x}(k) , \\textbf{x}(k+ m) \\rangle $ at different discrete time steps m (evolution provided by the network) and fixed k and we compared it with the result found with numerical integration.\n",
    "2) $\\textbf{x}_i (k)\\ \\text{vs}\\ \\textbf{x}_j (k)$ at different time steps k (evolution provided by the network)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figDir=\"figs\" # Is the directory that will contain all the images generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_corr_m=totXT.permute((2,0,1)).detach().numpy()\n",
    "Y_corr_m=totYT.permute((2,0,1)).detach().numpy()\n",
    "\n",
    "plt.rcParams['text.usetex'] = True\n",
    "\n",
    "fig,axs=plt.subplots(1,3,figsize=(15,5))\n",
    "ax1,ax2,ax3=axs\n",
    "ax1.set_title(r\"Auto-correlation true trajectory $\\langle \\textbf{x}(k) , \\textbf{x}(k+ m) \\rangle$\")\n",
    "ax1.set_xlabel(r\"Time-steps difference in frames m\")\n",
    "ax1.set_ylabel(r\"Pearson coefficient\")\n",
    "ax2.set_title(r\"Corr. true/pred. trajectory $\\langle \\textbf{x}(k+m) , \\textbf{y}(k+ m) \\rangle$\")\n",
    "ax2.set_xlabel(r\"Time-steps difference in frames $m$\")\n",
    "#ax2.set_ylabel(r\"Pearson coefficient\")\n",
    "ax3.set_title(r\"Auto-correlation predicted traj. $\\langle \\textbf{y}(k) , \\textbf{y}(k+ m) \\rangle$\")\n",
    "ax3.set_xlabel(r\"Time-steps difference in frames $m$\")\n",
    "#ax3.set_ylabel(r\"Pearson coefficient\")\n",
    "\n",
    "colors=[['navy','cornflowerblue','cyan'],\n",
    "        ['maroon','indianred','peachpuff'],\n",
    "        ['seagreen','limegreen','palegreen']]\n",
    "for i in range(coor):\n",
    "    X=range(0,len(X_corr_m[i]))\n",
    "    Y=[]\n",
    "    for ix in range(len(X)):\n",
    "        Y.append(pearsonr(X_corr_m[i][0],X_corr_m[i][ix])[0])\n",
    "    ax1.plot(X,Y,label=r\"$\\langle x_\"+str(i)+r\"(k), x_\"+str(i)+r\"(k+m) \\rangle$\",color=colors[0][i])\n",
    "    Y=[]\n",
    "    for ix in range(len(X)):\n",
    "        Y.append(pearsonr(X_corr_m[i][ix],Y_corr_m[i][ix])[0])\n",
    "    ax2.plot(X,Y,label=r\"$\\langle x_\"+str(i)+r\"(k+m), y_\"+str(i)+r\"(k+m) \\rangle$\",color=colors[1][i])\n",
    "    Y=[]\n",
    "    for ix in range(len(X)):\n",
    "        Y.append(pearsonr(Y_corr_m[i][0],Y_corr_m[i][ix])[0])\n",
    "    ax3.plot(X,Y,label=r\"$\\langle y_\"+str(i)+r\"(k), y_\"+str(i)+r\"(k+m) \\rangle$\",color=colors[2][i])\n",
    "\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "ax3.legend()\n",
    "plt.tight_layout()\n",
    "fig.savefig(f\"{figDir}/{exp[option-1]}-correlations.png\",dpi=600)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAN=np.random.randint(0,len(totXT[0].detach().numpy()))\n",
    "X_traj=totXT.permute((1,2,0)).detach().numpy()[RAN]\n",
    "Y_traj=totYT.permute((1,2,0)).detach().numpy()[RAN]\n",
    "\n",
    "fig,ax=plt.subplots(1,figsize=(5,5))\n",
    "ax.set_title(f\"Trajectory in phase space [initial condition \\#{RAN}]\")\n",
    "ax.set_xlabel(r\"$x_0(t)$\")\n",
    "ax.set_ylabel(r\"$x_1(t)$\")\n",
    "ax.plot(X_traj[0],X_traj[1],label=\"Trajectory\",linestyle='dotted',alpha=1,color='seagreen',zorder=0)\n",
    "ax.scatter(X_traj[0][0],X_traj[1][0],marker='o',color='maroon',label='Starting point $X(0)$',alpha=1,zorder=1)\n",
    "\n",
    "ax.plot(Y_traj[0],Y_traj[1],label=\"Predicted\",color='navy',zorder=0)\n",
    "ax.scatter(Y_traj[0][0],Y_traj[1][0],marker='x',s=100,color='black',label='Reconstructed $X(0)$',zorder=1)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "fig.savefig(f\"{figDir}/{exp[option-1]}-random_trajectory-#{RAN}.png\",dpi=600)\n",
    "\n",
    "if len(X_traj)>2:\n",
    "    fig3D = plt.figure()\n",
    "    ax3D = plt.axes(projection='3d')\n",
    "    \n",
    "    ax3D.set_title(f\"Trajectory in phase space [initial condition \\#{RAN}]\")\n",
    "    ax3D.set_xlabel(r\"$x_0(t)$\")\n",
    "    ax3D.set_ylabel(r\"$x_1(t)$\")\n",
    "    ax3D.set_zlabel(r\"$x_2(t)$\")\n",
    "    ax3D.plot3D (X_traj[0],X_traj[1],X_traj[2],label=\"Trajectory\",linestyle='dotted',alpha=1,color='seagreen',zorder=0)\n",
    "    ax3D.scatter(X_traj[0][0],X_traj[1][0],X_traj[2][0],marker='o',color='maroon',label='Starting point $X(0)$',alpha=1,zorder=1)\n",
    "\n",
    "    ax3D.plot(Y_traj[0],Y_traj[1],Y_traj[2],label=\"Predicted\",color='navy',zorder=0)\n",
    "    ax3D.scatter(Y_traj[0][0],Y_traj[1][0],Y_traj[2][0],marker='x',s=100,color='black',label='Reconstructed $X(0)$',zorder=1)\n",
    "    ax3D.legend()\n",
    "    plt.tight_layout()\n",
    "    fig3D.savefig(f\"{figDir}/{exp[option-1]}-3D_random_trajectory-#{RAN}.png\",dpi=600)\n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
